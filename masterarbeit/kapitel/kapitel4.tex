%%% TeX-master: "../main.tex"
% kapitel4.tex
\chapter{Konzept eines Vollautomatischen GUI-Testers}\label{chapter:conceptfullautoguitesting}


Das folgende Kapitel setzt sich mit der Idee des ``Vollautomatischen explorativen Crawler-Tests''
auseinander. Bestehende GUI-Tests wurden in den vorherigen Kapiteln betrachtet. Hier wird nun zunächst 
die Motivation für ein neues Konzept erläutert, sowie der potenzielle Einsatz und Nutzen desselben.
Im Anschluss werden Entscheidungen während der Entwicklung und Implementation beleuchtet.
Die genutzten Kernalgorithmen werden vorgestellt. Die letzte Sektion befasst sich mit der
Zustandserfassung und -verfolgung sowie der Modellierung eines Graphen bzw. Automaten, welcher
das Verhalten des getesteten Programms widerspiegelt.


\section{Fragestellung: Online oder Offline testen?}\label{section:offoronlinetesting}


Die erste Frage, die sich bei Konzeption eines Test-Tools stellt, ist, ob ein kompiliertes Programm
oder lediglich die Quelldateien untersucht werden sollen. Quellcode kann mithilfe von statischen
Methoden untersucht werden, welche keine Ausführung des Programms erfordern. Dies bezeichnet man
entsprechend als ``Offline''-Test \cite{offlinetesting}, eine Unterart des Modellbasierten Tests.
Letztendlich wird immer eine Art Pseudo-Programm erstellt bzw. kompiliert, welches die
Eigenschaften oder das Verhalten aus dem Quellcode übernehmen und danach dessen Einhaltung durch
das fertig kompilierte und ausgeführte Programm sicherstellen soll. Alternativ wird schon
im Quelltext selbst nach bekannten Problemstrukturen gesucht, also statische Analyse betrieben.

Der Vorteil liegt üblicherweise vor allen darin, dass eine solche Analyse unabhängig von der
Plattform betrieben werden kann und die Ergebnisse sich auf alle möglichen Endnutzer beziehen.
Im konkreten Fall soll aber Java Swing getestet werden, also ein Programm, welches vermutlich
bereits von sich aus sehr Plattformunabhängig ist (Eigenarten der JVM sind nicht üblicherweise
Bestandteil von Tests).

Ebenso treten eine Vielzahl von Problemen und gerade den Fehlern, die hiermit gesucht werden,
nur im Online-Fall auf. Besonders mögliche Fehler interner Implementationen bei gewissen ungewöhnlichen
Eingabemustern sind von Interesse. So wird der Tester aufgrund mangelnden Kontexts meist unsinnige
Eingaben tätigen, welche ein Mensch von sich aus nicht vornehmen würde. Dementsprechend könnten
diese auch Entwicklern und gewöhnlichen Testern entgangen sein. Ebenso werden grenzwertige
Zeichenketten bei jeder sich bietenden Möglichkeit verwendet, um Probleme bei der Zeichenverarbeitung
(eine grosse Fehlerquelle bei Programmen) aufzuzeigen.

Java Swing benutzt \textbf{OpenGL}\label{openglQQ}, welches aufgrund seines Konzepts als gewaltige
Black-Box Zustandsmaschine auf der Grafikkarte bzw. dessen Treiber
ohne direkte Debug-Anbindung an das betreibende Betriebssystem
häufig als übermässig Fehleranfällig und unnötig komplex im Entwicklungsprozess kritisiert wird.
Es existiert abgesehen von gleichzeitiger Überwachung der graphischen Ausgabeoberfläche
durch einen Prozess der ``Machine Vision'' bzw. des Maschinensehens keine Möglichkeit,
ohne menschliches Wirken visuelle Fehler zu erkennen. Fehler in der Darstellung oder
der graphischen Implementation wird dieses Konzept also nicht erkennen können.

Schlussendlich sind dynamisch erzeugte Inhalte für Offline-Ansätze im Allgemeinen
nicht zu erschliessen, da dies über die Möglichkeiten vordefinierter Modellanalyse herausgeht.
Im zu untersuchenden Fall von Java-GUI sind sogenannte anonyme Klassen aber keine
Seltenheit und müssten vom Crawler-Anteil der Testanwendung unbedingt miteinbezogen werden.

Es wird ein Online-Ansatz gewählt, die Testanwendung startet eine echte Instanz
der zu testenden Applikation und führt dann auf dieser (aus Sicht der Anwendung) reale
Eingaben durch.


\section{Implementation eines vollautomatischen GUI-Testers für Java Swing}\label{section:myfullautoguitest}


Existierende GUI-Testlösungen haben verschiedene Einschränkungen. Allen voran die
Notwendigkeit, Anwendungsspezifische Treiber zu implementieren oder ein Sollverhalten zu definieren.
Treiber können dadurch umgangen werden, dass eine allgemeingültige API verwendet wird (schliesslich 
muss jeder Nutzer mittels Maus und Tastatur mit der Oberfläche interagieren). Oder vielleicht
wäre es besser zu sagen, es wird nur ein einziger, allgemeingültiger Treiber implementiert.

Es existiert eine Schnittstelle namens ``Robot'' \cite{java7insel} für die Simulation nativer Eingaben
in einem Java Programm. Hierbei wird der Mauszeiger des Betriebssystems tatsächlich mittels
absoluten Koordinaten auf dem Bildschirm bewegt, und Mausklicks sowie Tastaturanschläge
werden an das Betriebssystem durchgegeben. Hier wurde gegen dieses Verfahren entschieden,
da es in der Praxis für den Fall des Konzepts kritische Nachteile hat:

Die hauptsächlich zu testende Anwendung FirstSpirit enthält viele sogenannte Dropdown-Elemente.
Damit werden Menüs bezeichnet, welche bei Betätigung aus einem Knopf heraus ausklappen und
weitere Elemente anzeigen, aber nur, so lange der Mauszeiger sich auf dem Umriss des
ursprünglichen Knopfes sowie des aufgeklappten Menüs befindet. Für eine Testanwendung
wie vorgeschlagen stellt dies ein schweres Hindernis das. Es müsste tatsächlich ein
Mauszeiger mit aus dem Kontext zu erschliessenden Informationen bewegt werden,
welcher sich innerhalb kontextabhängiger Koordinaten aufhalten muss. Kontext ist
aber gerade etwas, das vermieden werden soll. Ausserdem schränkt dies die möglichen
Eingabereihenfolgen der Testelemente empfindlich ein oder erzwingt zumindest
Zwischenschritte, um eine Eingabe erreichen zu können.

Da wir aber mit der Java Swing API arbeiten, und das zu testende Programm
in derselben Java Virtual Machine \cite{website:javaspecs} wie das Testprogramm 
ablaufen wird, können wir direkt auf die Datenstrukturen und Funktionen
des zu testenden Programms zugreifen. Insbesondere besteht jede graphische
Oberfläche, die mittels Java Swing implementiert wurde, aus Untertypen
bzw. Unterklassen einiger weniger Datentypen einheitlichen Verhaltens.
Diese sind in einer Baumstruktur von einer Wurzel aus angeordnet, von
der aus der Test beginnen soll. Die Auffindung und Adressierung dieser
Wurzel erfordert Kontext - zum Durchführen eines Tests muss der Tester schon
erfahren, was er überhaupt testen soll. Damit beginnt der initiale
Durchlauf der Crawler-Komponente.

Innerhalb dieser Baumstruktur sind alle sichtbaren graphischen Elemente
hierarchisch angeordnet, und zusätzlich noch instanzierte, aber nicht sichtbare
Elemente. Um auf das Beispiel der Dropdown-Elemente zurückzukommen, diese
wären im Baum, aber nicht sichtbar. Jedes Element, das weitere Elemente enthält,
ist eine Klasse des Typus ``Container''. Tatsächlich trifft dies auf eine
einzelne Klasse des FirstSpirit-Programms nicht zu, welches eine spezifische
Implementation erfordert - aber das ist eine Abweichung von der Java-Swing-API
und daher ist eine spezifische Lösung für das spezifische Problem zulässig.

Jeder Container wird also rekursiv auf weitere Elemente durchsucht.
Gefundene Elemente werden in eine Liste eingegeben, welche alle noch zu
testenden Komponenten der graphischen Oberfläche enthält. Nach erfolgtem
Durchlauf des Crawlers durch die Baumstruktur enthält die Liste also
alle Elemente, die betätigt werden können und möglicherweise eine Reaktion
des Programms hervorrufen. So sind zum Beispiel alle Knöpfe Klassen des
Typs ``AbstractButton''. Diese Klasse bietet eine einheitliche Schnittstelle,
um Events bzw. Ereignisse, die von Eingaben ausgelöst werden würden,
zu verarbeiten. 

Diese Ereignis-Schnittstelle wird ausgenutzt, um künstlich erstellte
Ereignisse direkt bei jeweiligen graphischen Elementen des zu testenden 
Programms einzureichen. So kann ein Mausklick oder ein Tastenanschlag 
auf der Tastatur simuliert werden, ohne dass die tatsächlichen Limitationen
der Eingabegeräte beachtet werden müssten. Insbesondere lassen sich so
auch Elemente der graphischen Oberfläche adressieren, welche aktiviert
aber momentan unsichtbar sind - die Dropdown-Elemente zum Beispiel.
So können die Schaltflächen, die eigentlich nur durch Betätigen des
Dropdown erreichbar sind, dennoch problemlos ausgelöst werden.

Die Reaktion auf einen solchen Tastendruck ist natürlich von primärem
Interesse eines Testers. Leider stellt sich nun eine Herausforderung
in mehrfacher Hinsicht. Zunächst einmal sind Schalter in einem 
Java-Programm keine Konsolen- oder Webapplikationen, insbesondere
heisst dies, es gibt keine Antwort, die man schlicht ablesen könnte.
Jegliche Reaktion muss aus dem Verhalten des zu testenden Programms
bzw. Überwachung seines Zustands geschlossen werden.

Den Zustand eines nicht-trivialen Java-Programms erschliessend
zu überwachen, ist ein hoffnungsloses Unterfangen. Es gibt zu
viele unabhängige Kontrollfäden bzw. Threads und interagierende
Komponenten, Seiteneffekte und undurchsichtige Datenstrukturen
(siehe auch dem Absatz über OpenGL auf Seite \pageref{openglQQ}).
Der Zustand muss also auf höherer Ebene überwacht werden.
Wenn das zu testende Programm einen neuen Bildschirm öffnet
bzw. ein Popup erstellt, erzeugt dies Ereignisse in der Java-Swing-API,
auf welche der Tester reagieren kann. Auf dieser hohen Ebene ist
es allerdings schwierig, Gleichheit zwischen Komponenten
festzustellen. Im Grunde kann nur der allgemein vorhandene Titel
eines Fensters herangezogen werden. Alle anderen Informationen
sind nicht zwangsläufig vorhanden oder wenig hilfreich.

Ein Weiteres Problem bei der Überwachung von Reaktionen auf
Eingaben ist die Designentscheidung der Java-Swing-API,
Eingaben in einer globalen Verarbeitungsliste zu lagern
und sie in einem getrennten Kontrollfaden zu verarbeiten.
Insbesondere kann daher nicht garantiert werden,
dass eine getätigte Eingabe auch bis zum Zeitpunkt x
bereits verarbeitet wurde. Die einzige Abhilfe für dieses
Problem sind einstellbare Zeitintervalle zwischen
den Eingabeereignissen, die gross genug gewählt werden,
dass das zu testende Programm mit praktisch absoluter
Zuversicht bereits dazu gekommen ist, eine vorherige
Eingabe zu verarbeiten, bevor eine neue getätigt wird.

Nach Praxiserfahrung reicht hier bereits ein Wert von
wenigen Dutzend Millisekunden. Da realitätsnahe
Eingaben simuliert werden sollen, würde es auch wenig Sinn
machen, Eingaben noch schneller erfolgen zu lassen. Kein Mensch
wäre in der Lage, so schnell so viele verschiedene Knöpfe
zu drücken. Ein mögliches Problem stellt sich allerdings,
wenn die Verarbeitung einer Eingabe durch das Programm länger dauert,
als diese Wartezeit vorsieht - da es sich um mehrfach getrennte
Kontrollflüsse handelt, gibt es keine Möglichkeit,
festzustellen, wann die Verarbeitung einer Eingabe abgeschlossen ist.

Folglich können schon neue Eingaben in die Warteschleife
eingefügt werden, während das Programm noch mit der Verarbeitung
vorheriger Instanzen beschäftigt ist, und insbesondere kann
dadurch bei einem sich neu öffnendem Fenster bzw. einer Reaktion
der getesteten Applikation nicht mit Sicherheit davon ausgegangen
werden, dass die zuletzt getätigte Eingabe dafür verantwortlich zeichnet.

Die Herausforderung in diesem Zusammenhang ist der vollständige Test
aller auftretenden Komponenten, die Eingaben akzeptieren, wobei aber
die die Komponenten enthaltenen Fenster jederzeit aufgrund einer Eingabe
schliessen können. Diese Fenster müssen wieder geöffnet werden, und dafür
muss die Frage beantwortet werden können, welche getätigte Eingabe zum
Öffnen dieses spezifischen Fensters geführt hat.

Da jede Testerinstanz
eine nach dem Crawldurchlauf und Mischung der Ergebnisse eine von 
der Reihenfolge her immutable Liste enthält, lässt sich dieses Problem aber
einfach lösen: Eine Testerinstanz gibt bei Verlust ihres getesteten Fensters
an die übergeordnete Instanz zurück, welche dann rückwärts in der Liste
schreitet und Eingaben durchführt, um das verlorene Fenster wieder aufzurufen.
Eventuell auftretende falsche, schon abgehandelte Fenster werden ignoriert.
Sobald das gesuchte Fenster wieder auftritt, geht der Kontrollfluss wieder an
die zwischenzeitlich pausierte untergeordnete Instanz, und diese setzt ihren
Test auf den restlichen, bisher ungetesteten Bestandteilen des Fensters fort.
Dieser Algorithmus wird auf Seite \pageref{alg:autotesterwindowloss} erläutert.

Die Hauptschleife des Testprogramms wird durch den Algorithmus auf auf Seite 
\pageref{alg:autotestermain} beschrieben, die Behandlung von auftretenden
Fenstern auf Seite \pageref{alg:autotesterpopup}. Der Tester selbst erzeugt
ebenfalls eine graphische Oberfläche, dies ist allerdings in erster Linie
ein Platzhalter für eventuelle Tests mit menschlicher Beteiligung und enthält
lediglich eine Schaltfläche zum Abbruch des laufenden Tests sowie eine
kontinuierliche Zeitanzeige, um eventuelle Deadlocks bzw. Verklemmungen \cite{deadlocks},
die während des Tests auftreten, zu erkennen.


\begin{algorithm} \SetAlgoLined
	\KwData{Laufender Test $T$, neues Fenster/Popup $P$}
	\KwResult{Alle an $P$ anhaengigen Komponenten wurden getestet, Test $T$ setzt fort}
	vorherige Testinstanz $T$ anhalten, sichert Zustand\;
	$Tn \longleftarrow Komponententester(P)$\;
	vorherige Testinstanz $T$ starten, Zustand wiederherstellen\;
	\caption{Popupbehandlung}
	\label{alg:autotesterpopup}
\end{algorithm}

\begin{algorithm} \SetAlgoLined
	\KwData{Wurzelkomponente/Fenster $A$, Liste von Problemstrings $StrL$;}
	\KwResult{Alle an $A$ anhaengigen Komponenten wurden getestet}
	Komponentenliste $C: \longleftarrow A$ auf Komponenten durchsuchen\;
	$C$ ein Mal zufaellig durchmischen\;
	\For{Komponente $k \in C$}
	{
		\If{$k \in Eingabeelemente$}
		{
			$k \longleftarrow ``Nutzereingabe''$\;
			kurze Wartezeit (um GUI reagieren zu lassen)
		}
		\ElseIf{$k \in Texteingabeelemente$}
		{
			\For{String $s \in StrL$}
			{
				$k \longleftarrow ``Eintippen'' StrL$\;
				$k \longleftarrow ``Bestaetigung''$\;
				sehr kurze Wartezeit (um GUI reagieren zu lassen)
			}
			$k \longleftarrow ``Eintippen'' zufaelliges s \in StrL$\;
		}
		\If{$Auftreten neues Fenster/Popup P$}
		{
			Popupbehandlung($P$)\;
		}
	}
	\caption{Komponententester}
	\label{alg:autotestermain}
\end{algorithm}

\begin{algorithm} \SetAlgoLined
	\KwData{Laufender Test $T$, vorheriger Test $Ta$, Fenster $F$ wurde vor Beendigung des Tests vom Programm geschlossen}
	\KwResult{Test $T$ setzt auf neuem, identischen Fenster $Fn$ fort}
	$Ts \longleftarrow$ laufende Testinstanz $T$ anhalten, sichert Zustand\;
	$T \longleftarrow Ta$, $T$ in Rückwärtslauf schalten\;
	\For{vorherige betätigte Komponente $k \in C(T)$}
	{
		\If{Auftreten Fenster $Fn$ mit $Fn == F$}
		{
			$T$ in Vorwärtslauf schalten\;
			Testinstanz $T$ wieder anhalten, sichert Zustand\;
			$T \longleftarrow Ts$, $F$ mit $Fn$ ersetzen, Zustand wiederherstellen\;
			Diese Suchschleife beenden, $T$ fortfahren lassen\;
		}
	}
	
	\caption{Verhalten bei Verlust des zu testenden Fensters}
	\label{alg:autotesterwindowloss}
\end{algorithm}


\section{Problematische String-Eingaben}\label{section:naughtystrings}

Es wird eine online erhältliche, quelloffen gepflegte Liste aus Entwicklerkreisen verwendet, 
die ``Big List of Naughty Strings'' \cite{website:naughty-strings}. Diese enthält unter viele bekannte
Vertreter typischer Fehler oder Lücken bei der Verarbeitung von Zeichenketten in Programmen und
insbesondere auch im Internet. Es finden sich Zeichendarstellungen reservierter Begriffe wie
``null'' oder ``true'', SQL-Befehle, HTML und Javascript, exotische Unicode-Zeichen wie das
``zero-width space'' \cite{unicodezerowidth} oder auch diverse DOS- oder Unix-spezifische
Anweisungen oder Optionen für Kommandozeilen.

Ziel ist es hierbei primär, mögliche durch Lücken in der Zeichenverarbeitung ausgelöste Probleme oder gar
Abstürze des Programms schnell herbeizuführen, damit diese diagnostiziert und behoben werden können.
Dies wird auch als ``Input Sanitization'' bzw. Eingabevalidierung bzw. -prüfung bezeichnet. 
Obwohl dieses Verfahren primär zur Verteidigung gegen Skript-Angriffe auf Webseiten dient
\cite{website:eingabepruefung}, zählt eine wenig sinnvolle, aber dennoch mögliche Eingabe, 
die das zu testende Programm in der Ausführung beeinträchtigt oder sogar stoppt, klar zur 
Softwarequalität und sollte korrekt behandelt werden. Eine Fehlermeldung an den Nutzer zum
Beispiel ist eine völlig legitime Reaktion, eine unbehandelte Ausnahme dagegen nicht.


\section{Zustandserfassung, -sicherung und -verfolgung sowie Kontrollmechanismen}\label{section:statemonitoring}

Wieso Graphstruktur
Knotengleichheit - Probleme Java Blackbox
JGraphT, graphml Format
