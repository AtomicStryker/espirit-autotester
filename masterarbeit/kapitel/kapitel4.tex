%%% TeX-master: "../main.tex"
% kapitel4.tex
\chapter{Konzept eines Vollautomatischen GUI-Testers}\label{chapter:conceptfullautoguitesting}


Das folgende Kapitel setzt sich mit der Idee des \glqq{}Vollautomatischen explorativen Crawler-Tests\grqq{}
auseinander. Bestehende GUI-Tests wurden in den vorherigen Kapiteln betrachtet. Hier wird nun zunächst 
die Motivation für ein neues Konzept erläutert, sowie der potenzielle Einsatz und Nutzen desselben.
Im Anschluss werden Entscheidungen während der Entwicklung und Implementation beleuchtet.
Die genutzten Kernalgorithmen werden vorgestellt. Die letzte Sektion befasst sich mit der
Zustandserfassung und -verfolgung sowie der Modellierung eines Graphen bzw. Automaten, welcher
das Verhalten des getesteten Programms widerspiegelt.


\section{Fragestellung: Online oder Offline testen?}\label{section:offoronlinetesting}


Die erste Frage, die sich bei Konzeption eines Test-Tools stellt, ist, ob ein kompiliertes Programm
oder lediglich die Quelldateien untersucht werden sollen. Quellcode kann mithilfe von statischen
Methoden untersucht werden, welche keine Ausführung des Programms erfordern. Dies bezeichnet man
entsprechend als \glqq{}Offline\grqq{}-Test \cite{offlinetesting}, eine Unterart des Modellbasierten Tests.
Letztendlich wird immer eine Art Pseudo-Programm erstellt bzw. kompiliert, welches die
Eigenschaften oder das Verhalten aus dem Quellcode übernehmen und danach dessen Einhaltung durch
das fertig kompilierte und ausgeführte Programm sicherstellen soll. Alternativ wird schon
im Quelltext selbst nach bekannten Problemstrukturen gesucht, also statische Analyse betrieben.

Der Vorteil liegt üblicherweise vor allen darin, dass eine solche Analyse unabhängig von der
Plattform betrieben werden kann und die Ergebnisse sich auf alle möglichen Endnutzer beziehen.
Im konkreten Fall soll aber Java Swing getestet werden, also ein Programm, welches vermutlich
bereits von sich aus sehr Plattformunabhängig ist (Eigenarten der JVM sind nicht üblicherweise
Bestandteil von Tests).

Ebenso treten eine Vielzahl von Problemen und gerade den Fehlern, die hiermit gesucht werden,
nur im Online-Fall auf. Besonders mögliche Fehler interner Implementationen bei gewissen ungewöhnlichen
Eingabemustern sind von Interesse. So wird der Tester aufgrund mangelnden Kontexts meist unsinnige
Eingaben tätigen, welche ein Mensch von sich aus nicht vornehmen würde. Dementsprechend könnten
diese auch Entwicklern und gewöhnlichen Testern entgangen sein. Ebenso werden grenzwertige
Zeichenketten bei jeder sich bietenden Möglichkeit verwendet, um Probleme bei der Zeichenverarbeitung
(eine grosse Fehlerquelle bei Programmen) aufzuzeigen.

Java Swing benutzt \textbf{OpenGL}\label{openglQQ}, welches aufgrund seines Konzepts als gewaltige
Black-Box Zustandsmaschine auf der Grafikkarte bzw. dessen Treiber
ohne direkte Debug-Anbindung an das betreibende Betriebssystem
häufig als übermässig Fehleranfällig und unnötig komplex im Entwicklungsprozess kritisiert wird.
Es existiert abgesehen von gleichzeitiger Überwachung der graphischen Ausgabeoberfläche
durch einen Prozess der \glqq{}Machine Vision\grqq{} bzw. des Maschinensehens keine Möglichkeit,
ohne menschliches Wirken visuelle Fehler zu erkennen. Fehler in der Darstellung oder
der graphischen Implementation wird dieses Konzept also nicht erkennen können.

Schlussendlich sind dynamisch erzeugte Inhalte für Offline-Ansätze im Allgemeinen
nicht zu erschliessen, da dies über die Möglichkeiten vordefinierter Modellanalyse herausgeht.
Im zu untersuchenden Fall von Java-GUI sind sogenannte anonyme Klassen aber keine
Seltenheit und müssten vom Crawler-Anteil der Testanwendung unbedingt miteinbezogen werden.

Es wird ein Online-Ansatz gewählt, die Testanwendung startet eine echte Instanz
der zu testenden Applikation und führt dann auf dieser (aus Sicht der Anwendung) reale
Eingaben durch.


\section{Implementation eines vollautomatischen GUI-Testers für Java Swing}\label{section:myfullautoguitest}


Existierende GUI-Testlösungen haben verschiedene Einschränkungen. Allen voran die
Notwendigkeit, Anwendungsspezifische Treiber zu implementieren oder ein Sollverhalten zu definieren.
Treiber können dadurch umgangen werden, dass eine allgemeingültige API verwendet wird (schliesslich 
muss jeder Nutzer mittels Maus und Tastatur mit der Oberfläche interagieren). Oder vielleicht
wäre es besser zu sagen, es wird nur ein einziger, allgemeingültiger Treiber implementiert.

Es existiert eine Schnittstelle namens \glqq{}Robot\grqq{} \cite{java7insel} für die Simulation nativer Eingaben
in einem Java Programm. Hierbei wird der Mauszeiger des Betriebssystems tatsächlich mittels
absoluten Koordinaten auf dem Bildschirm bewegt, und Mausklicks sowie Tastaturanschläge
werden an das Betriebssystem durchgegeben. Hier wurde gegen dieses Verfahren entschieden,
da es in der Praxis für den Fall des Konzepts kritische Nachteile hat:

Die hauptsächlich zu testende Anwendung FirstSpirit enthält viele sogenannte Dropdown-Elemente.
Damit werden Menüs bezeichnet, welche bei Betätigung aus einem Knopf heraus ausklappen und
weitere Elemente anzeigen, aber nur, so lange der Mauszeiger sich auf dem Umriss des
ursprünglichen Knopfes sowie des aufgeklappten Menüs befindet. Für eine Testanwendung
wie vorgeschlagen stellt dies ein schweres Hindernis das. Es müsste tatsächlich ein
Mauszeiger mit aus dem Kontext zu erschliessenden Informationen bewegt werden,
welcher sich innerhalb kontextabhängiger Koordinaten aufhalten muss. Kontext ist
aber gerade etwas, das vermieden werden soll. Ausserdem schränkt dies die möglichen
Eingabereihenfolgen der Testelemente empfindlich ein oder erzwingt zumindest
Zwischenschritte, um eine Eingabe erreichen zu können.

Da wir aber mit der Java Swing API arbeiten, und das zu testende Programm
in derselben Java Virtual Machine \cite{website:javaspecs} wie das Testprogramm 
ablaufen wird, können wir direkt auf die Datenstrukturen und Funktionen
des zu testenden Programms zugreifen. Insbesondere besteht jede graphische
Oberfläche, die mittels Java Swing implementiert wurde, aus Untertypen
bzw. Unterklassen einiger weniger Datentypen einheitlichen Verhaltens.
Diese sind in einer Baumstruktur von einer Wurzel aus angeordnet, von
der aus der Test beginnen soll. Die Auffindung und Adressierung dieser
Wurzel erfordert Kontext - zum Durchführen eines Tests muss der Tester schon
erfahren, was er überhaupt testen soll. Damit beginnt der initiale
Durchlauf der Crawler-Komponente.

Innerhalb dieser Baumstruktur sind alle sichtbaren graphischen Elemente
hierarchisch angeordnet, und zusätzlich noch instanzierte, aber nicht sichtbare
Elemente. Um auf das Beispiel der Dropdown-Elemente zurückzukommen, diese
wären im Baum, aber nicht sichtbar. Jedes Element, das weitere Elemente enthält,
ist eine Klasse des Typus \glqq{}Container\grqq{}. Tatsächlich trifft dies auf eine
einzelne Klasse des FirstSpirit-Programms nicht zu, welches eine spezifische
Implementation erfordert - aber das ist eine Abweichung von der Java-Swing-API
und daher ist eine spezifische Lösung für das spezifische Problem zulässig.

Jeder Container wird also rekursiv auf weitere Elemente durchsucht.
Gefundene Elemente werden in eine Liste eingegeben, welche alle noch zu
testenden Komponenten der graphischen Oberfläche enthält. Nach erfolgtem
Durchlauf des Crawlers durch die Baumstruktur enthält die Liste also
alle Elemente, die betätigt werden können und möglicherweise eine Reaktion
des Programms hervorrufen. So sind zum Beispiel alle Knöpfe Klassen des
Typs \glqq{}AbstractButton\grqq{}. Diese Klasse bietet eine einheitliche Schnittstelle,
um Events bzw. Ereignisse, die von Eingaben ausgelöst werden würden,
zu verarbeiten. 

Diese Ereignis-Schnittstelle wird ausgenutzt, um künstlich erstellte
Ereignisse direkt bei jeweiligen graphischen Elementen des zu testenden 
Programms einzureichen. So kann ein Mausklick oder ein Tastenanschlag 
auf der Tastatur simuliert werden, ohne dass die tatsächlichen Limitationen
der Eingabegeräte beachtet werden müssten. Insbesondere lassen sich so
auch Elemente der graphischen Oberfläche adressieren, welche aktiviert
aber momentan unsichtbar sind - die Dropdown-Elemente zum Beispiel.
So können die Schaltflächen, die eigentlich nur durch Betätigen des
Dropdown erreichbar sind, dennoch problemlos ausgelöst werden.

Die Reaktion auf einen solchen Tastendruck ist natürlich von primärem
Interesse eines Testers. Leider stellt sich nun eine Herausforderung
in mehrfacher Hinsicht. Zunächst einmal sind Schalter in einem 
Java-Programm keine Konsolen- oder Webapplikationen, insbesondere
heisst dies, es gibt keine Antwort, die man schlicht ablesen könnte.
Jegliche Reaktion muss aus dem Verhalten des zu testenden Programms
bzw. Überwachung seines Zustands geschlossen werden.

Den Zustand eines nicht-trivialen Java-Programms erschliessend
zu überwachen, ist ein hoffnungsloses Unterfangen. Es gibt zu
viele unabhängige Kontrollfäden bzw. Threads und interagierende
Komponenten, Seiteneffekte und undurchsichtige Datenstrukturen
(siehe auch dem Absatz über OpenGL auf Seite \pageref{openglQQ}).
Der Zustand muss also auf höherer Ebene überwacht werden.
Wenn das zu testende Programm einen neuen Bildschirm öffnet
bzw. ein Popup erstellt, erzeugt dies Ereignisse in der Java-Swing-API,
auf welche der Tester reagieren kann. Auf dieser hohen Ebene ist
es allerdings schwierig, Gleichheit zwischen Komponenten
festzustellen. Im Grunde kann nur der allgemein vorhandene Titel
eines Fensters herangezogen werden. Alle anderen Informationen
sind nicht zwangsläufig vorhanden oder wenig hilfreich.

Ein Weiteres Problem bei der Überwachung von Reaktionen auf
Eingaben ist die Designentscheidung der Java-Swing-API,
Eingaben in einer globalen Verarbeitungsliste zu lagern
und sie in einem getrennten Kontrollfaden zu verarbeiten.
Insbesondere kann daher nicht garantiert werden,
dass eine getätigte Eingabe auch bis zum Zeitpunkt x
bereits verarbeitet wurde. Die einzige Abhilfe für dieses
Problem sind einstellbare Zeitintervalle zwischen
den Eingabeereignissen, die gross genug gewählt werden,
dass das zu testende Programm mit praktisch absoluter
Zuversicht bereits dazu gekommen ist, eine vorherige
Eingabe zu verarbeiten, bevor eine neue getätigt wird.

Nach Praxiserfahrung ist hier ein Wert von deutlich über
einer Sekunde nötig, da ansonsten Probleme auftreten. Da realitätsnahe
Eingaben simuliert werden sollen, würde es auch wenig Sinn
machen, Eingaben noch schneller erfolgen zu lassen. Kein Mensch
wäre in der Lage, so schnell so viele verschiedene Knöpfe
zu drücken. Ein mögliches Problem stellt sich allerdings,
wenn die Verarbeitung einer Eingabe durch das Programm länger dauert,
als diese Wartezeit vorsieht - da es sich um mehrfach getrennte
Kontrollflüsse handelt, gibt es keine Möglichkeit,
festzustellen, wann die Verarbeitung einer Eingabe abgeschlossen ist.

Folglich können schon neue Eingaben in die Warteschleife
eingefügt werden, während das Programm noch mit der Verarbeitung
vorheriger Instanzen beschäftigt ist, und insbesondere kann
dadurch bei einem sich neu öffnendem Fenster bzw. einer Reaktion
der getesteten Applikation nicht mit Sicherheit davon ausgegangen
werden, dass die zuletzt getätigte Eingabe dafür verantwortlich zeichnet.

Die Herausforderung in diesem Zusammenhang ist der vollständige Test
aller auftretenden Komponenten, die Eingaben akzeptieren, wobei aber
die die Komponenten enthaltenen Fenster jederzeit aufgrund einer Eingabe
schliessen können. Diese Fenster müssen wieder geöffnet werden, und dafür
muss die Frage beantwortet werden können, welche getätigte Eingabe zum
Öffnen dieses spezifischen Fensters geführt hat.

Da jede Testerinstanz
eine nach dem Crawldurchlauf und Mischung der Ergebnisse eine von 
der Reihenfolge her immutable Liste enthält, lässt sich dieses Problem aber
einfach lösen: Eine Testerinstanz gibt bei Verlust ihres getesteten Fensters
an die übergeordnete Instanz zurück, welche dann rückwärts in der Liste
schreitet und Eingaben durchführt, um das verlorene Fenster wieder aufzurufen.
Eventuell auftretende falsche, schon abgehandelte Fenster werden ignoriert.
Sobald das gesuchte Fenster wieder auftritt, geht der Kontrollfluss wieder an
die zwischenzeitlich pausierte untergeordnete Instanz, und diese setzt ihren
Test auf den restlichen, bisher ungetesteten Bestandteilen des Fensters fort.
Dieser Algorithmus wird auf Seite \pageref{alg:autotesterwindowloss} erläutert.

Die Hauptschleife des Testprogramms wird durch den Algorithmus auf auf Seite 
\pageref{alg:autotestermain} beschrieben, die Behandlung von auftretenden
Fenstern auf Seite \pageref{alg:autotesterpopup}. Der Tester selbst erzeugt
ebenfalls eine graphische Oberfläche, dies ist allerdings in erster Linie
ein Platzhalter für eventuelle Tests mit menschlicher Beteiligung und enthält
lediglich eine Schaltfläche zum Abbruch des laufenden Tests sowie eine
kontinuierliche Zeitanzeige, um eventuelle Deadlocks bzw. Verklemmungen \cite{deadlocks},
die während des Tests auftreten, zu erkennen.


\begin{algorithm} \SetAlgoLined
	\KwData{Laufender Test $T$, neues Fenster/Popup $P$}
	\KwResult{Alle an $P$ anhaengigen Komponenten wurden getestet, Test $T$ setzt fort}
	vorherige Testinstanz $T$ anhalten, sichert Zustand\;
	$Tn \longleftarrow Komponententester(P)$\;
	vorherige Testinstanz $T$ starten, Zustand wiederherstellen\;
	\caption{Popupbehandlung}
	\label{alg:autotesterpopup}
\end{algorithm}

\begin{algorithm} \SetAlgoLined
	\KwData{Wurzelkomponente/Fenster $A$, Liste von Problemstrings $StrL$;}
	\KwResult{Alle an $A$ anhaengigen Komponenten wurden getestet}
	Komponentenliste $C: \longleftarrow A$ auf Komponenten durchsuchen\;
	$C$ ein Mal zufaellig durchmischen\;
	\For{Komponente $k \in C$}
	{
		\If{$k \in Eingabeelemente$}
		{
			$k \longleftarrow \glqq{}Nutzereingabe\grqq{}$\;
			kurze Wartezeit (um GUI reagieren zu lassen)
		}
		\ElseIf{$k \in Texteingabeelemente$}
		{
			\For{String $s \in StrL$}
			{
				$k \longleftarrow \glqq{}Eintippen\grqq{} StrL$\;
				$k \longleftarrow \glqq{}Bestaetigung\grqq{}$\;
				sehr kurze Wartezeit (um GUI reagieren zu lassen)
			}
			$k \longleftarrow \glqq{}Eintippen\grqq{} zufaelliges s \in StrL$\;
		}
		\If{Auftreten neues Fenster/Popup $P$}
		{
			Popupbehandlung($P$)\;
		}
	}
	\caption{Komponententester}
	\label{alg:autotestermain}
\end{algorithm}

\begin{algorithm} \SetAlgoLined
	\KwData{Laufender Test $T$, vorheriger Test $Ta$, Fenster $F$ wurde vor Beendigung des Tests vom Programm geschlossen}
	\KwResult{Test $T$ setzt auf neuem, identischen Fenster $Fn$ fort}
	$Ts \longleftarrow$ laufende Testinstanz $T$ anhalten, sichert Zustand\;
	$T \longleftarrow Ta$, $T$ in Rückwärtslauf schalten\;
	\For{vorherige betätigte Komponente $k \in C(T)$}
	{
		\If{Auftreten Fenster $Fn$ mit $Fn == F$}
		{
			$T$ in Vorwärtslauf schalten\;
			Testinstanz $T$ wieder anhalten, sichert Zustand\;
			$T \longleftarrow Ts$, $F$ mit $Fn$ ersetzen, Zustand wiederherstellen\;
			Diese Suchschleife beenden, $T$ fortfahren lassen\;
		}
	}
	
	\caption{Verhalten bei Verlust des zu testenden Fensters}
	\label{alg:autotesterwindowloss}
\end{algorithm}


\section{Problematische String-Eingaben}\label{section:naughtystrings}

Es wird eine online erhältliche, quelloffen gepflegte Liste aus Entwicklerkreisen verwendet, 
die \glqq{}Big List of Naughty Strings\grqq{} \cite{website:naughty-strings}. Diese enthält unter viele bekannte
Vertreter typischer Fehler oder Lücken bei der Verarbeitung von Zeichenketten in Programmen und
insbesondere auch im Internet. Es finden sich Zeichendarstellungen reservierter Begriffe wie
\glqq{}null\grqq{} oder \glqq{}true\grqq{}, SQL-Befehle, HTML und Javascript, exotische Unicode-Zeichen wie das
\glqq{}zero-width space\grqq{} \cite{unicodezerowidth} oder auch diverse DOS- oder Unix-spezifische
Anweisungen oder Optionen für Kommandozeilen.

Ziel ist es hierbei primär, mögliche durch Lücken in der Zeichenverarbeitung ausgelöste Probleme oder gar
Abstürze des Programms schnell herbeizuführen, damit diese diagnostiziert und behoben werden können.
Dies wird auch als \glqq{}Input Sanitization\grqq{} bzw. Eingabevalidierung bzw. -prüfung bezeichnet. 
Obwohl dieses Verfahren primär zur Verteidigung gegen Skript-Angriffe auf Webseiten dient
\cite{website:eingabepruefung}, zählt eine wenig sinnvolle, aber dennoch mögliche Eingabe, 
die das zu testende Programm in der Ausführung beeinträchtigt oder sogar stoppt, klar zur 
Softwarequalität und sollte korrekt behandelt werden. Eine Fehlermeldung an den Nutzer zum
Beispiel ist eine völlig legitime Reaktion, eine unbehandelte Ausnahme dagegen nicht.

Je nach Betriebssystem führen unterschiedliche Symbole und Begriffe z.B. als Dateinamen
manchmal zu sonderbaren Effekten und Fehlermeldungen oder sind schlicht verboten.
Beispiele hierfür wären \textbf{COM} oder auch von geschweiften Klammern \{\} umschlossene
Begriffe unter Windows, oder \textbf{dev} unter Linux. Programme, die Ihre eigenen
Dateioperationen mit wählbaren Dateinamen durchführen, sehen häufig nicht eine vollständige
Behandlung all dieser möglichen Sonderfälle vor, und die Programmiersprache Java erzwingt
trotz vorgegebenen I\\O Ausnahmebehandlungen nicht, alle Eventualitäten abzudecken.


\section{Zustandserfassung, -sicherung und -verfolgung sowie Kontrollmechanismen}\label{section:statemonitoring}

Um eine Überprüf-, Nachvollzieh- und Reproduzierbarkeit der vom Automatischen Tester
durchgeführen Eingaben sicherzustellen, müssen diese bei jedem Testdurchlauf erschöpfend
mitprotokolliert werden. Da die Erstellung eines Modells der zu testenden Anwendung 
ebenfalls als Ziel definiert wurde, bietet sich ein Graph als Datenstruktur an. Die Analogie
eines solchen sowohl zum Java-AWT/Java-Swing Datenmodell als auch zu den meisten 
Automatendarstellungen der Informatik lässt eine einfache und Intuitive Implementation
erhoffen. Auch lassen sich die von einer Applikation geöffneten Fenster als Knoten und die
dorthin führenden Eingaben als Knotenübergänge auffassen, und es existieren
fertige Java-Bibliotheken für normierte Graphdarstellung. Für dieses Projekt genutzt
werden die Quelloffene Graphbibliothek GraphT \cite{website:jgrapht} sowie die
ebenfalls offene Visualisierungsplattform Gephi \cite{website:gephi}.

Sobald man die Frage nach dem \textbf{Wie} beantwortet hat, stellt sich als Nächstes
eine Ähnliche nach dem \textbf{Was}. Unglücklicherweise sind Java-Applikationen der realen
Welt nicht nach akademischen Maßstäben gläsern und überschaubar. Kurz nach dem
Start eines konkreten Testdurchlaufs für FirstSpirit durch den Autotester zeigt der
Java-Debugger bereits 20 verschiedene Threads oder Kontrollfäden an, die Alle auf
die eine oder andere Weise den Tester oder das Testobjekt beeinflussen können.
Java ist objektorientiert \cite{java7insel}, was im Gegensatz zu den Alternativen 
wie imperativen oder funktionellen Programmen in der Theorie erlaubt, jede laufende 
Instanz eines Programms in einen für Menschen verständlichen Datensatz zu übersetzen.

In der Praxis zeigt sich aber, dass die Masse an Kontrollfäden, Objekten und
sich gegenseitig beeinflussenden Nebeneffekten eine vollständige Zustandserfassung
und - verfolgung äusserst impraktikabel, wenn auch nicht völlig unmöglich, macht.
Das zu testende Programm muss folglich als \glqq{}Black Box\grqq{} verstanden werden.
Obwohl wir technisch in der Lage sind, die Inhalte einzusehen, ist die genaue
Funktion ein Rätsel, und wir können lediglich Rückschlüsse aus beobachtetem
Verhalten ziehen. Für unsere Zustandserfassung heisst dies, dass wir lediglich
die Klasse einer dargestellten Oberflächenelements sowie aus globalen
Schnittstellen erhältliche Informationen nutzen können, um einen beliebigen Zustand
von einem Anderen zu unterscheiden. 

Diese Methodik hängt bis zu einem gewissen Grad von der jeweiligen Implementation 
des getesteten Programms ab und ist nicht frei von möglicher Ambivalenz,
insbesondere bei generellen, häufig benutzten Elementen - aber wenn
das Verhalten eines Objekts von Instruktionen und nicht von Daten abhängt,
gibt es für den Tester keine praktikable Möglichkeit, dies festzustellen
oder ohne Kontext irgendetwas Sinnvolles mit der Information anzufangen.

Ein Beispiel hierfür ist im Rahmen des FirstSpirit-Programms die Klasse
\glqq{}SearchDialog\grqq{}. Sie dient der Auswahl einer Datei oder eines Ordners
des Betriebssystems. Die Klasse beinhaltet keine Datenfelder, die für
eine Identifizierung einer konkreten Instanz hilfreich wären. Sie ist
Unterklasse von SelfDisposingDialog, welches ebenfalls keine Felder
enthält, und schliesslich JDialog, eine Basisklasse der Java-Swing-API.
Diese garantiert nun die Präsenz eines Titels für jedwede Instanz
seiner Klassen, selbst wenn dieser nicht definiert oder leer sein sollte.
Worin unterscheiden sich nun verschiedene Instanzen von \glqq{}SearchDialog\grqq{}?

Die Antwort ist leider: In den Anweisungen, die an die Schnittstellen
des jeweiligen Objekts geschrieben wurden. Wir können dazu auf einen
aussagekräftigen, eindeutigen Titel des Suchfensters hoffen. Die
Anweisungen lesen und vergleichen zu wollen wäre zwar theoretisch
Möglich, aber praktisch nutzlos. Die Instanz ist von Ihrem Nutzungskontext
abhängig, und Kontext ist etwas, dass der Autotester nicht verstehen kann.
Lediglich die Eingaben, die zu dem Suchfenster geführt haben,
lassen weitere Rückschlüsse darauf zu, wofür es dienen könnte.

Für den Autotester und eine für Menschen verständliche Protokollierung
wurde die Lösung einer eigenen \textbf{toString()} Methode gewählt.
Hierbei nimmt der Tester ein beliebiges darstellbares Objekt aus dem Testprogramm,
vergleicht es mit einer Reihe von der Java-Swing-API vorgegebenen
Objekten und Schnittstellen, und wählt eine passende Textdarstellung aus.
Üblicherweise ist dies der \glqq{}simple Classname\grqq{}, der einfache Klassenname,
da dieser nach gängigen Java-Konventionen den Nutzen einer Klasse zumindest
andeutet, kombiniert mit den möglicherweise vorhandenen kritischen Daten
der spezifischen Typklasse. Im Falle eines Fensters beispielsweise wäre
dies die Zeichenkette, die in der Titelzeile angezeigt wird. Im Fall
eines beschrifteten Knopfes die Beschriftung. Im Fall eines Glyph-Knopfes
ohne jegliche Beschriftung ziehen wir den \glqq{}Tooltip\grqq{} heran,
die vom Programmierer vorgesehene helfende Zeichenkette, die angezeigt
wird, wenn der Nutzer seinen Mauszeiger kurz über das betreffende Symbol hält.
Wir verlassen uns also auf gängige Programmierpraxis sowie Eigenarten der 
Java-Datenstrukturen, um ähnliche Instanzen zu identifizieren.

Eine eigene Graphimplementation für das Projekt zu verfassen wäre
außerhalb des Rahmens, daher wurde nach einem möglichst verbreitetem
Datenstandard und passenden Bibliotheken gesucht. Die Wahl fiel auf
die Quelloffenen Projekte der Graphbibliothek GraphT \cite{website:jgrapht} 
sowie der Visualisierungsplattform Gephi \cite{website:gephi}.
Das gewählte Datenformat ist \textbf{.graphml} \cite{website:graphml}.
Es handelt sich hierbei um einfache Textdateien im xml-Format,
welche auch menschlich noch lesbar und verständlich sind, und notfalls
auch editiert oder korrigiert werden könnten. 

Innerhalb des Testers erstellt JGraphT während des Testvorgangs 
ein Datenmodell des Graphen der getesteten Applikation. Nach erfolgreichem
Abschluss desselben wird das Resultat in besagtem graphml-Format
in einer eindeutig nach dem Testdatum benannten Datei abgespeichert.
Diese Datei ist dann zwar vollständig und auch von Menschen lesbar,
aber noch absolut undurchsichtig. Visualisierung ist notwendig,
um die Informationen in eine verständliche Form zu bringen.
Hierzu wird wahlweise Gephi verwendet. Es öffnet graphml-Dateien
und erlaubt die automatische Neuanordnung eines Graphen auf dem
Bildschirm, um maximale Ansehnlichkeit zu erzielen.

Nach einigen Probeläufen erwies sich der mitgelieferte 
Yifan-Hu-Algorithmus \cite{hu2005efficient} als am sinnvollsten,
um einen komplexen Graph sternförmig auszubreiten. Ein beispielhaftes
Ergebnis lässt sich auf Seite \pageref{fig:model_firstspirit_notext}
begutachten. In der Grundeinstellung werden die von GraphT
abgespeicherten Knotendaten bzw. Programmzustände nicht angezeigt.
Diese relativ umfangreichen Zeichenketten erfordern für eine minimale
Lesbarkeit noch manuelles Verschieben und Sortieren der Graphknoten.
Ist dies aber erfolgt, erhält man aus dem Durchlauf eines blind testenden
Programms aber tatsächlich eine deckende Abbildung der getesteten
Applikation bzw. Ihrer möglichen Fensterdarstellungen. Zu sehen
ist ein solches finales Resultat auf Seite \pageref{fig:model_freespirit_06.10.2015}.
